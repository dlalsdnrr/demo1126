from __future__ import annotations

import os
import threading
import io
import base64
from typing import Optional, Dict, Any
import time
import difflib
import requests # <-- requests ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
import tempfile # ğŸ’¡ [ì¶”ê°€ë¨] Faster Whisperê°€ íŒŒì¼ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ì„ì‹œ íŒŒì¼ ìƒì„±ì„ ìœ„í•´ ì¶”ê°€

from flask import Blueprint, jsonify, request

# --- ğŸ’¡ config ëª¨ë“ˆì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸° ---
import config 

# --- STT ëª¨ë“ˆ ë³€ê²½ (ETRI -> Faster Whisper) ---
STT_AVAILABLE = False
WHISPER_MODEL = None # ğŸ’¡ [ìˆ˜ì •ë¨] Faster Whisper ëª¨ë¸ì„ ì €ì¥í•  ì „ì—­ ë³€ìˆ˜

try:
    from faster_whisper import WhisperModel # ğŸ’¡ [ìˆ˜ì •ë¨] faster_whisper ì„í¬íŠ¸
    STT_AVAILABLE = True
    print("--- INFO: Faster Whisper STT module loaded.")
except ImportError:
    print("Warning: 'faster-whisper' module not installed. STT unavailable.")
    print("--- Please run: pip install faster-whisper ---")
    WhisperModel = None # type: ignore
except Exception as e: # pragma: no cover
    print(f"Error during Faster Whisper initialization: {e}")
    WhisperModel = None # type: ignore


# --- TTS (edge-tts + pydub) í†µí•© (ë³€ê²½ ì—†ìŒ) ---
try:
    import edge_tts
    import asyncio
    from pydub import AudioSegment
    from pydub.effects import speedup
    TTS_AVAILABLE = True
    USE_EDGE_TTS = True
    print("--- INFO: edge-tts module loaded.")
except Exception: # pragma: no cover
    edge_tts = None
    AudioSegment = None
    speedup = None
    TTS_AVAILABLE = False
    USE_EDGE_TTS = False
    print("Warning: edge-tts, pydub or FFmpeg not installed. Audio processing/TTS unavailable.")
    

# ===================================================================
# ğŸ’¡ [ìˆ˜ì •ë¨] load_whisper_model í•¨ìˆ˜ (Faster Whisper ë¡œì§ìœ¼ë¡œ)
# ===================================================================
def load_whisper_model(model_name: str = "base") -> Optional[Any]:
    """Faster Whisper ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    global WHISPER_MODEL, STT_AVAILABLE

    if not STT_AVAILABLE:
        print("--- ERROR: Faster Whisper module not imported. Cannot load model.")
        return None
    
    if WHISPER_MODEL is None:
        try:
            print(f"--- INFO: Loading Faster Whisper STT model ('{model_name}')...")
            # ğŸ’¡ CPUì— ìµœì í™”ëœ "base" ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤ (Code 2ì˜ ì„¤ì •ê³¼ ë™ì¼)
            WHISPER_MODEL = WhisperModel(model_name, device="cpu", compute_type="int8", cpu_threads=4)
            print("--- INFO: Faster Whisper model loaded successfully.")
        except Exception as e:
            print(f"--- ERROR: Failed to load Faster Whisper model: {e}")
            STT_AVAILABLE = False # ë¡œë“œ ì‹¤íŒ¨ ì‹œ STT ë¹„í™œì„±í™”
            WHISPER_MODEL = None
            
    return WHISPER_MODEL
# ===================================================================


# --- TTS í•¨ìˆ˜ (ë³€ê²½ ì—†ìŒ) ---
async def speak_edge_tts_to_base64(text: str, voice="ko-KR-SunHiNeural", speed_factor=1.1) -> Optional[str]:
    if not USE_EDGE_TTS or not AudioSegment:
        print("--- ERROR: edge-tts or pydub not available.")
        return None
    print(f"--- INFO: TTS generation (edge-tts) for: {text[:30]}...")
    try:
        communicate = edge_tts.Communicate(text, voice)
        audio_data = b""
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                audio_data += chunk["data"]
        audio_io = io.BytesIO(audio_data)
        song = AudioSegment.from_mp3(audio_io)
        if speed_factor != 1.0:
            song = speedup(song, playback_speed=speed_factor)
        output_buffer = io.BytesIO()
        song.export(output_buffer, format="mp3", bitrate="64k") # ğŸ’¡ ì €ìš©ëŸ‰ MP3ë¡œ ë³€ê²½
        output_buffer.seek(0)
        return base64.b64encode(output_buffer.read()).decode('utf-8')
    except Exception as e:
        print(f"--- ERROR: edge-tts failed: {e}")
        return None

def get_tts_base64(text: str) -> Optional[str]:
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
    return loop.run_until_complete(speak_edge_tts_to_base64(text))


class VoiceAssistant:
    def __init__(self) -> None:
        # ğŸ’¡ [ìˆ˜ì •ë¨] Faster Whisper ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        self._whisper_model = load_whisper_model("base")
        self._exit_keywords = []
        
        # --- í‚¤ì›Œë“œ ë° ì„ ìˆ˜ ë°ì´í„° (ë³€ê²½ ì—†ìŒ) ---
        self.KEYWORDS = {
            "íƒ€ìœ¨": ["íƒ€ìœ¨", "íƒ€ì´ìœ¨", "íƒ€ìœ ìœ¨", "íƒ€ìœ„", "íƒ€ì´ìœ„", "íƒ€ìœ ", "ë‹¤ìœ¨", "íƒ€ë‰¼", "íƒ€ë£°", "íƒ€ìœ ë¥¼", "íƒ€ìœ ë¦¬", "íƒ€ìœ¨ì€", "íƒ€ìœ¨ì´", 
                   "ë‹¤ìš”ë˜", "íƒ€ì´ìœ ", "íƒ€ìš”ë¥¼", "íƒ€ìš”ìœ¨", "ë‹¤ìœ¡", "ë‹¤ì´ìœ¨", "ë‹¤ì´ìœ ", "ë‹¤ìœ "],
            "í™ˆëŸ°": ["í™ˆëŸ°", "í™ëŸ°", "í™ˆë¡¬", "í™ë¡ ", "í›”ëŠ”", "í™ˆë¡ ", "í™ˆëˆˆ", "í—˜ë¡ ", "í˜¸ë„ˆ", "í™ˆë„ˆ", "í™ˆë„Œ", "í™ˆëŸ°ì€", "í™ˆëŸ°ì´", "í™ˆëŸ°ê°œìˆ˜",
                   "í™ë‚¨", "í™ˆë‚¨", "í™ëŸ¼", "í™ˆë„˜", "í ëŸ°", "ìŒë€", "ì—„ë‚¨"],
            "ì•ˆíƒ€": ["ì•ˆíƒ€", "ì•™íƒ€", "ì•ˆ íƒ€", "ì•”íƒ€", "ì•ˆíƒˆ", "ì•ˆíƒ‘", "ì•„íƒ€", "ì•ˆíƒ€ëŠ”", "ì•ˆíƒ€ê°€", "ì•„ì•ˆíƒ€", "ì•ˆíƒ€ê°œìˆ˜",
                   "ì•ˆë‚˜", "ì•ˆíƒ€ë¡œ", "ì•ˆë‹¤", "ì•ˆë‹¬", "ì•˜ë‹¤"]
        }
        self.PLAYER_ALIASES = {
            "ê¹€ì˜ì›…": ["ê¹€ì˜ì›…", "ê¸°ëª…ì›…", "ê¹€í˜•ì›…", "ì‚¼ì„± ê¹€ì˜ì›…", "ê¹€ì˜ì›…ì´", "ê¸°ì˜ì›…", "ê¹€ì˜", "ì˜ì›…", "ì˜ì›…ì´", "ê¹€ì—¬ì›…"],
            "ë¬¸í˜„ë¹ˆ": ["ë¬¸í˜„ë¹ˆ", "ë¬¸í˜„ë¹ˆì´", "ë¬¸í˜„ë¹ˆì€", "í•œí™” ë¬¸í˜„ë¹ˆ", "ë¬´ë…„ë¹ˆ", "ë¬¸í˜„ë¯¼", "ë¬´í˜„ë¹ˆ", "í˜„ë¹ˆ", "í˜„ë¹ˆì´", "ë¬¸í˜„"],
            "ë…¸ì‹œí™˜": ["ë…¸ì‹œí™˜", "ë…¸ì‹œí™˜ì´", "ë…¸ì‹œí™˜ì€", "í•œí™” ë…¸ì‹œí™˜", "ë…¸ì‹œì™„", "ë…¸ì‹œí•œ", "ìš”ì‹œí™˜", "ì‹œí™˜", "ì‹œí™˜ì´", "ë¡¯ì‹œí™˜"],
            "ë¦¬ë² ë¼í† ": ["ë¦¬ë² ë¼í† ", "ì´ë² ë¼í† ", "ë¦¬ë² ë¼", "ì´ë² ë¼", "í•œí™” ë¦¬ë² ë¼í† ", "ë¦¬ë² ë¼ë„", "ì´ë² ë¼ë„", "ë‹ˆë² ë¼í† ", "ë‹ˆë² ë¼ë„"],
            "ê¹€íƒœí›ˆ": ["ê¹€íƒœí›ˆ", "ê¹€íƒœìš´", "ê¹€íƒœí¬", "ì‚¼ì„± ê¹€íƒœí›ˆ", "ê¹€ëŒ€í›ˆ", "ê¹€íƒœí›„", "íƒœí›ˆ", "íƒœí›ˆì´", "ê¹€íƒœ"],
            "ìµœì¬í›ˆ": ["ìµœì¬í›ˆ", "ì²´ì¬í›ˆ", "ì·Œì¬í›ˆ", "í•œí™” ìµœì¬í›ˆ", "ìµœì œí›ˆ", "ì±„ì¬í›ˆ", "ì¬í›ˆ", "ì¬í›ˆì´", "ìµœì¬"],
            "ì±„ì€ì„±": ["ì±„ì€ì„±", "ì±„ì€ì„±ì´", "í•œí™” ì±„ì€ì„±", "ìµœì€ì„±", "ì²´ì€ì„±", "ì€ì„±", "ì€ì„±ì´", "ì±„ì€"],
            "í•˜ì£¼ì„": ["í•˜ì£¼ì„", "ì•„ì£¼ì„", "í™”ì£¼ì„", "í•œí™” í•˜ì£¼ì„", "í•˜ì£¼ì„œ", "í•˜ì£¼", "ì£¼ì„", "ì£¼ì„ì´", "ì•„ì£¼ì„"],
            "êµ¬ììš±": ["êµ¬ììš±", "êµ¬ììš±ì´", "ì‚¼ì„± êµ¬ììš±", "ììš±ì´", "êµ¬ììš°", "êµ¬ìì˜¥", "ììš±", "ê³ ììš±", "êµ¬ì"],
            "ì´ì¬í˜„": ["ì´ì¬í˜„", "ì´ì¬í˜„ì´", "ì‚¼ì„± ì´ì¬í˜„", "ì´ì¬í˜•", "ì´ì¬ì—°", "ì¬í˜„", "ì¬í˜„ì´", "ì´ì œí˜„"],
            "ë””ì•„ì¦ˆ": ["ë””ì•„ì¦ˆ", "ë””ì•„ìŠ¤", "ì‚¼ì„± ë””ì•„ì¦ˆ", "ë””ì•„ì¦ˆëŠ”", "ë””ì•„ìŠ¤", "ë””ì•„ì§€", "ë””ì•„", "ë””ì•„ì¦ˆê°€"],
            "ì†ì•„ì„­": ["ì†ì•„ì„­", "ì†ì•„ì„­ì´", "í•œí™” ì†ì•„ì„­", "ì†Œë‚˜ì„­", "ì†ì•„", "ì•„ì„­", "ì•„ì„­ì´", "ì†ì•„ì„ "],
            "ê¹€ì„±ìœ¤": ["ê¹€ì„±ìœ¤", "ê¹€ì„±ìœ¤ì´", "ì‚¼ì„± ê¹€ì„±ìœ¤", "ê¹€ì„±ìš©", "ê¹€ì„±ìœ ", "ì„±ìœ¤", "ì„±ìœ¤ì´", "ê¹€ì„±"],
            "ê¹€ì§€ì°¬": ["ê¹€ì§€ì°¬", "ê¹€ì§€ì°¬ì´", "ì‚¼ì„± ê¹€ì§€ì°¬", "ê¹€í¬ì°¬", "ê¹€ê¸°ì°¬", "ê¹€ì£¼ì°¬", "ì§€ì°¬", "ì§€ì°¬ì´", "ê¹€ì§€"],
            "ê°•ë¯¼í˜¸": ["ê°•ë¯¼í˜¸", "ê°•ë¯¼í˜¸ëŠ”", "ì‚¼ì„± ê°•ë¯¼í˜¸", "ê°•ë¯¸ë…¸", "ê°•ë¯¼", "ë¯¼í˜¸", "ë¯¼í˜¸ê°€"],
            "ì‹¬ìš°ì¤€": ["ì‹¬ìš°ì¤€", "ì‹¬ìš°ì¤€ì´", "í•œí™” ì‹¬ìš°ì¤€", "ì‹ ìš°ì¤€", "ì‹œë¬´ì¤€", "ìš°ì¤€", "ìš°ì¤€ì´", "ì‹œë¬´"]
        }
        self.PLAYERS_DATA = {
            "ê¹€ì˜ì›…": { "íƒ€ìœ¨": 0.625, "í™ˆëŸ°": 3, "ì•ˆíƒ€": 10 },
            "ë¬¸í˜„ë¹ˆ": { "íƒ€ìœ¨": 0.444, "í™ˆëŸ°": 2, "ì•ˆíƒ€": 8 },
            "ë…¸ì‹œí™˜": { "íƒ€ìœ¨": 0.429, "í™ˆëŸ°": 2, "ì•ˆíƒ€": 9 },
            "ë¦¬ë² ë¼í† ": { "íƒ€ìœ¨": 0.389, "í™ˆëŸ°": 1, "ì•ˆíƒ€": 7 },
            "ê¹€íƒœí›ˆ": { "íƒ€ìœ¨": 0.353, "í™ˆëŸ°": 2, "ì•ˆíƒ€": 6 },
            "ìµœì¬í›ˆ": { "íƒ€ìœ¨": 0.353, "í™ˆëŸ°": 0, "ì•ˆíƒ€": 6 },
            "ì±„ì€ì„±": { "íƒ€ìœ¨": 0.350, "í™ˆëŸ°": 0, "ì•ˆíƒ€": 7 },
            "í•˜ì£¼ì„": { "íƒ€ìœ¨": 0.350, "í™ˆëŸ°": 0, "ì•ˆíƒ€": 7 },
            "êµ¬ììš±": { "íƒ€ìœ¨": 0.313, "í™ˆëŸ°": 0, "ì•ˆíƒ€": 5 },
            "ì´ì¬í˜„": { "íƒ€ìœ¨": 0.294, "í™ˆëŸ°": 1, "ì•ˆíƒ€": 5 },
            "ë””ì•„ì¦ˆ": { "íƒ€ìœ¨": 0.278, "í™ˆëŸ°": 0, "ì•ˆíƒ€": 5 },
            "ì†ì•„ì„­": { "íƒ€ìœ¨": 0.263, "í™ˆëŸ°": 0, "ì•ˆíƒ€": 5 },
            "ê¹€ì„±ìœ¤": { "íƒ€ìœ¨": 0.261, "í™ˆëŸ°": 0, "ì•ˆíƒ€": 6 },
            "ê¹€ì§€ì°¬": { "íƒ€ìœ¨": 0.190, "í™ˆëŸ°": 0, "ì•ˆíƒ€": 4 },
            "ê°•ë¯¼í˜¸": { "íƒ€ìœ¨": 0.188, "í™ˆëŸ°": 1, "ì•ˆíƒ€": 3 },
            "ì‹¬ìš°ì¤€": { "íƒ€ìœ¨": 0.077, "í™ˆëŸ°": 0, "ì•ˆíƒ€": 1 }
        }

    # --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ë³€ê²½ ì—†ìŒ) ---
    def _fuzzy_match(self, text: str, candidates: list[str], threshold=0.65) -> bool:
        for word in candidates:
            if word in text:
                return True
        for candidate in candidates:
            if difflib.SequenceMatcher(None, text, candidate).ratio() > threshold:
                return True
        return False

    # ===================================================================
    # ğŸ’¡ [STT í•¨ìˆ˜ êµì²´] _transcribe_faster_whisper
    # ===================================================================
    def _transcribe_faster_whisper(self, wav_audio_bytes: bytes) -> Optional[str]:
        """Faster Whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        if not STT_AVAILABLE or not self._whisper_model:
            print("--- ERROR: Faster Whisper STT not available or model not loaded.")
            return None
            
        print("--- INFO: Transcribing audio with Faster Whisper...")
        
        temp_file_path = None
        try:
            # 1. ì„ì‹œ íŒŒì¼ ìƒì„± (WAV ë°”ì´íŠ¸ ì‚¬ìš©)
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_file:
                temp_file.write(wav_audio_bytes)
                temp_file_path = temp_file.name
            
            # 2. Faster Whisperë¡œ íŒŒì¼ ë³€í™˜ (Code 2ì˜ VAD ì˜µì…˜ ì‚¬ìš©)
            segments, _ = self._whisper_model.transcribe(
                temp_file_path,
                language="ko", # í•œêµ­ì–´
                beam_size=5,
                vad_filter=True, # ìŒì„± êµ¬ê°„ ê°ì§€(VAD) í™œì„±í™”
                vad_parameters={"min_silence_duration_ms": 500} # 0.5ì´ˆ ë¬µìŒ
            )
            
            # 3. ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì¡°ë¦½
            text = " ".join(segment.text.strip() for segment in segments).lower()
            return text if text else None

        except Exception as e:
            print(f"--- ERROR: Faster Whisper transcription failed: {e}")
            print("--- INFO: This might be due to 'ffmpeg' not being installed on your system.")
            return None
        finally:
            # 4. ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if temp_file_path and os.path.exists(temp_file_path):
                try:
                    os.remove(temp_file_path)
                except Exception: # pragma: no cover
                    pass # ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ì‹œì—ë„ í”„ë¡œê·¸ë¨ì€ ê³„ì†ë˜ì–´ì•¼ í•¨
            
    def _transcribe(self, audio: Any) -> Optional[str]:
        """STT ì—”ì§„ ë³€ê²½ìœ¼ë¡œ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ."""
        print("--- WARNING: _transcribe function called, but Faster Whisper is active.")
        return None
    # ===================================================================

    # --- _find_player, _find_keyword, _get_reply (ë³€ê²½ ì—†ìŒ) ---
    def _find_player(self, text: str) -> Optional[str]:
        if not text: return None
        for canonical_name, aliases in self.PLAYER_ALIASES.items():
            if self._fuzzy_match(text, aliases):
                return canonical_name
        return None

    def _find_keyword(self, text: str) -> Optional[str]:
        if not text: return None
        if "ë‹¤ìš”ë˜" in text: 
            return "íƒ€ìœ¨"
        for keyword, similar_words in self.KEYWORDS.items():
            if self._fuzzy_match(text, similar_words):
                return keyword
        return None

    def _get_reply(self, text: str, player_name: Optional[str], keyword: Optional[str]) -> str:
        # ğŸ’¡ [ìˆ˜ì •ë¨] STT ì‹¤íŒ¨ ì‹œ(None) ì‘ë‹µ
        if not text:
            return "ìŒì„± ì¸ì‹ì´ ì˜ ë˜ì§€ ì•Šì•˜ì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?"
        if not player_name:
            # ğŸ’¡ [ê°œì„ ] STT ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ë³´ì—¬ì£¼ê¸°
            return f"ì£„ì†¡í•´ìš”, ì„ ìˆ˜ ì´ë¦„ì„ ì°¾ì§€ ëª»í–ˆì–´ìš”. (ì¸ì‹ëœ ë‚´ìš©: {text})"
        if not keyword:
            return f"{player_name} ì„ ìˆ˜ì˜ ì–´ë–¤ ì •ë³´ê°€ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?"
            
        player_info = self.PLAYERS_DATA.get(player_name)
        if player_info is None:
            return f"ì£„ì†¡í•´ìš”, {player_name} ì„ ìˆ˜ì˜ ê¸°ë¡ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        value = player_info.get(keyword)
        if value is None:
            return f"ì£„ì†¡í•´ìš”, {player_name} ì„ ìˆ˜ì˜ {keyword} ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        if keyword == "íƒ€ìœ¨":
            return f"{player_name} ì„ ìˆ˜ì˜ íƒ€ìœ¨ì€ {value:.3f}ì…ë‹ˆë‹¤."
        elif keyword == "í™ˆëŸ°":
            return f"{player_name} ì„ ìˆ˜ì˜ í™ˆëŸ°ì€ {value}ê°œì…ë‹ˆë‹¤."
        elif keyword == "ì•ˆíƒ€":
            return f"{player_name} ì„ ìˆ˜ì˜ ì•ˆíƒ€ëŠ” {value}ê°œì…ë‹ˆë‹¤."
        else:
            return f"{player_name} ì„ ìˆ˜ì˜ {keyword}ì€(ëŠ”) {value}ì…ë‹ˆë‹¤."
            
    # ===================================================================
    # ğŸ’¡ [ìˆ˜ì •ë¨] process_ptt_audio í•¨ìˆ˜ (Faster Whisper ë¡œì§ìœ¼ë¡œ)
    # ===================================================================
    def process_ptt_audio(self, audio_file_storage) -> Dict[str, Any]:
        """PTT ì˜¤ë””ì˜¤ë¥¼ ì²˜ë¦¬í•˜ê³ , í…ìŠ¤íŠ¸ì™€ Base64 ì˜¤ë””ì˜¤ê°€ í¬í•¨ëœ JSONì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        start_time = time.time()

        user_text = None
        reply_text = None
        player_name = None
        keyword = None
        display_user_text = "..."
        audio_base64 = None
                
        # ğŸ’¡ [ìˆ˜ì •ë¨] STT_AVAILABLE (Faster Whisper) ê¸°ì¤€ìœ¼ë¡œ ë³€ê²½
        if not STT_AVAILABLE or not AudioSegment or not TTS_AVAILABLE:
            reply_text = "ìŒì„± ì²˜ë¦¬ ëª¨ë“ˆ(Faster Whisper/Pydub/Edge-TTS)ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            if not STT_AVAILABLE:
                reply_text += " (Whisper ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„œë²„ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.)"
        else:
            try:
                # --- 1. ì˜¤ë””ì˜¤ ë¡œë“œ ë° STTìš© WAV ë°ì´í„°ë¡œ ë³€í™˜ (pydub) ---
                load_start = time.time()
                audio_segment = AudioSegment.from_file(audio_file_storage)
                
                # 16kHz, Mono, 16-bit (Whisper ê¶Œì¥ ìŠ¤í™)
                audio_segment = audio_segment.set_frame_rate(16000).set_channels(1).set_sample_width(2)
                
                # 'wav' í¬ë§·ì˜ ë°”ì´íŠ¸ë¡œ ì¶”ì¶œ
                wav_audio_io = io.BytesIO()
                audio_segment.export(wav_audio_io, format="wav")
                audio_data_for_stt = wav_audio_io.getvalue()
                
                print(f"--- TIME: Audio Load/Convert for STT (WAV): {time.time() - load_start:.3f}s")
                
                # --- 2. STT (ìŒì„± -> í…ìŠ¤íŠ¸) - Faster Whisper ì‚¬ìš© ---
                stt_start = time.time()
                # ğŸ’¡ [ìˆ˜ì •ë¨] _transcribe_etri -> _transcribe_faster_whisper í˜¸ì¶œ
                user_text = self._transcribe_faster_whisper(audio_data_for_stt) 
                print(f"--- TIME: STT Transcription (Faster Whisper): {time.time() - stt_start:.3f}s")
                print(f"--- INFO: STT Text: {user_text}")

                # --- 3. NLU (í…ìŠ¤íŠ¸ -> ì˜ë„) ---
                nlu_start = time.time()
                if user_text:
                    player_name = self._find_player(user_text)
                    keyword = self._find_keyword(user_text)
                print(f"--- TIME: NLU Processing: {time.time() - nlu_start:.3f}s")

                # --- 4. í…ìŠ¤íŠ¸ ë³´ì • ---
                if player_name and keyword:
                    display_user_text = f"{player_name} ì„ ìˆ˜ {keyword} ì•Œë ¤ì¤˜"
                elif user_text:
                    display_user_text = user_text
                else:
                    # ğŸ’¡ STTê°€ ì‹¤íŒ¨(None)í–ˆê±°ë‚˜ ë¹ˆ í…ìŠ¤íŠ¸ì¼ ë•Œ
                    display_user_text = "ìŒì„± ì¸ì‹ ì‹¤íŒ¨"
                
                # --- 5. ì‘ë‹µ ìƒì„± ---
                reply_text = self._get_reply(user_text, player_name, keyword)
                
            except Exception as e:
                print(f"--- ERROR: Failed to process PTT audio: {e}")
                reply_text = "ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

        # --- 6. TTS (AI í…ìŠ¤íŠ¸ -> AI ìŒì„±) ë° Base64 ì¸ì½”ë”© ---
        tts_start = time.time()
        if TTS_AVAILABLE and reply_text:
            audio_base64 = get_tts_base64(reply_text) # <-- ì‹¤ì‹œê°„ ìƒì„±
        else:
            audio_base64 = None
            if not TTS_AVAILABLE:
                print("--- WARNING: TTS is not available, skipping audio generation.")
        
        print(f"--- TIME: TTS Generation: {time.time() - tts_start:.3f}s")
        
        total_time = time.time() - start_time
        print(f"--- TIME: Total process time: {total_time:.3f}s")
                
        # --- 7. ìµœì¢… JSON ë°˜í™˜ ---
        return {
            "ok": True,
            "display_user_text": display_user_text,
            "reply_text": reply_text,
            "audio_base64": audio_base64
        }
    # ===================================================================


# --- ì‹±ê¸€í†¤ ë° Blueprint (ë³€ê²½ ì—†ìŒ) ---
_singleton: Optional[VoiceAssistant] = None

def get_assistant() -> VoiceAssistant:
    """VoiceAssistant ì‹±ê¸€í†¤ ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _singleton
    if _singleton is None:
        _singleton = VoiceAssistant()
    return _singleton


voice_bp = Blueprint("voice", __name__)


@voice_bp.route("/api/voice/process_ptt", methods=["POST"])
def api_voice_process_ptt():
    """PTT ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë°›ì•„ ì²˜ë¦¬í•˜ê³  JSON ì‘ë‹µì„ ë°˜í™˜í•˜ëŠ” API"""
    va = get_assistant()
    
    audio_file = request.files.get('audio')
    if not audio_file:
        return jsonify({"ok": False, "error": "No audio file provided"}), 400

    response_data = va.process_ptt_audio(audio_file)

    if not response_data.get("ok"):
        return jsonify({"ok": False, "error": "Failed to process audio"}), 500

    return jsonify(response_data)
