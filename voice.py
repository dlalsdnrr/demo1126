from __future__ import annotations

import os
import threading
import io 
import base64 # ğŸ’¡ [ë³µì›] Base64 ì„í¬íŠ¸
from typing import Optional, Dict, Any

from flask import Blueprint, jsonify, request 

# --- STT (Faster Whisper) ---
try:
    from faster_whisper import WhisperModel
    import numpy as np 
except Exception: # pragma: no cover
    WhisperModel = None
    np = None
    print("Warning: faster-whisper or numpy not installed. Voice input unavailable.")

# ğŸ’¡ [ë³µì›] gTTS ë° Pydub ì„í¬íŠ¸
try:
    from gtts import gTTS
    from pydub import AudioSegment
    from pydub.effects import speedup
    TTS_AVAILABLE = True
except Exception: # pragma: no cover
    gTTS = None
    AudioSegment = None
    speedup = None
    TTS_AVAILABLE = False
    print("Warning: gTTS or pydub not installed, or FFmpeg is missing. TTS unavailable.")

try:
    import librosa
except Exception: # pragma: no cover
    librosa = None
    print("Warning: librosa not installed. VAD (Trimming) will be disabled.")


WHISPER_MODEL = None 

def load_whisper_model():
    """Faster Whisper ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    global WHISPER_MODEL
    if WHISPER_MODEL is None and WhisperModel is not None:
        try:
            # ğŸ’¡ğŸ’¡ğŸ’¡ --- [ì†ë„ ìµœì í™” 1] --- ğŸ’¡ğŸ’¡ğŸ’¡
            # "base" -> "tiny"ë¡œ ë³€ê²½í•˜ì—¬ STT ì†ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
            WHISPER_MODEL = WhisperModel("tiny", device="cpu", compute_type="int8", cpu_threads=4)
            print("--- INFO: Faster Whisper 'tiny' model loaded successfully.")
            # ğŸ’¡ğŸ’¡ğŸ’¡ --- [ìµœì í™” ì™„ë£Œ] --- ğŸ’¡ğŸ’¡ğŸ’¡
        except Exception as e:
            print(f"--- ERROR: Failed to load Whisper model: {e}")
            pass
    return WHISPER_MODEL


class VoiceAssistant:
    def __init__(self) -> None:
        self._gtts_lang = "ko"
        self._whisper_model = load_whisper_model()

        # (í‚¤ì›Œë“œ ëª©ë¡ì€ ë³€ê²½ ì—†ì´ ê·¸ëŒ€ë¡œ ìœ ì§€)
        self._exit_keywords = [
            "ì¢…ë£Œ", "ê·¸ë§Œ", "ëŒ€í™” ì¢…ë£Œ", "ë", "ë‚˜ê°€ê¸°",
            "ì¢…ë£Œí•´", "ì¢…ë£Œìš”", "ì´ì œ ê·¸ë§Œ", "ì¢…ë‡¨","ì¢…ìš”", "ì´ì œëì–´"
        ]
        self.KEYWORDS = {
            "íƒ€ìœ¨": ["íƒ€ìœ¨", "íƒ€ì´ìœ¨", "íƒ€ìœ ìœ¨", "íƒ€ìœ„", "íƒ€ì´ìœ„", "íƒ€ìœ ", "ë‹¤ìœ¨", "íƒ€ë‰¼", "íƒ€ë£°", "íƒ€ìœ ë¥¼", "íƒ€ìœ ë¦¬", "íƒ€ìœ¨ì€", "íƒ€ìœ¨ì´"],
            "í™ˆëŸ°": ["í™ˆëŸ°", "í™ëŸ°", "í™ˆë¡¬", "í™ë¡ ", "í›”ëŠ”", "í™ˆë¡ ", "í™ˆëˆˆ", "í—˜ë¡ ", "í˜¸ë„ˆ", "í™ˆë„ˆ", "í™ˆë„Œ", "í™ˆëŸ°ì€", "í™ˆëŸ°ì´", "í™ˆëŸ°ê°œìˆ˜"],
            "ì•ˆíƒ€": ["ì•ˆíƒ€", "ì•™íƒ€", "ì•ˆ íƒ€", "ì•”íƒ€", "ì•ˆíƒˆ", "ì•ˆíƒ‘", "ì•„íƒ€", "ì•ˆíƒ€ëŠ”", "ì•ˆíƒ€ê°€", "ì•„ì•ˆíƒ€", "ì•ˆíƒ€ê°œìˆ˜"]
        }
        self.PLAYER_ALIASES = {
            "ê¹€ì§€ì°¬": ["ê¹€ì§€ì°¬", "ê¹€ì§€ì°½", "ê¹€ì§€ì°¨", "ê¹€ì§€ì°¨ë‹ˆ", "ê¹€ì§€ì°¬ì´", "ê¹€ì§€ì²­", "ê¹€ì§€ì°¨ëŠ”", "ê¹€ì§€ì°¬ì€", "ê¸°ì§€ì°¬", "ê¹€ì§€ì°¾"],
            "êµ¬ììš±": ["êµ¬ììš±", "êµ¬ìì˜¥", "êµ¬ììš°", "êµ¬ìì˜¤", "êµ¬ììš±ì´", "êµ¬ìì˜¤ê¸°", "ê³ ììš±", "êµ¬ììš±ì€", "êµ¬ììš°ê¸°", "êµ¬ììš´", "êµ¬ìêµ¬"],
            "ë¥˜í˜„ì§„": ["ë¥˜í˜„ì§„", "ìœ í˜„ì§„", "ë‰´í˜„ì§„", "ìœ í˜„ì‹ ", "ë¥˜í˜„ì‹ ", "ìœ í˜„ì§€", "ë¥˜í˜„ì§€", "ìœ í˜„ì§€ëŠ”", "ë¥˜í˜„ì§€ëŠ”", "ìœ í˜„ì§€ë‹ˆ", "ë£¨í˜„ì§„"]
        }
        self.PLAYERS_DATA = {
            "ê¹€ì§€ì°¬": { "íƒ€ìœ¨": 0.285, "í™ˆëŸ°": 1, "ì•ˆíƒ€": 80 },
            "êµ¬ììš±": { "íƒ€ìœ¨": 0.315, "í™ˆëŸ°": 22, "ì•ˆíƒ€": 155 },
            "ë¥˜í˜„ì§„": { "íƒ€ìœ¨": 0.150, "í™ˆëŸ°": 0, "ì•ˆíƒ€": 5 }
        }

    # ğŸ’¡ğŸ’¡ğŸ’¡ --- [gTTS í•¨ìˆ˜ ë³µì›] --- ğŸ’¡ğŸ’¡ğŸ’¡
    def _say(self, text: str) -> Optional[io.BytesIO]:
        """í…ìŠ¤íŠ¸ë¥¼ gTTS MP3 ì˜¤ë””ì˜¤ ë²„í¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        if not text or not TTS_AVAILABLE:
            return None
        print(f"--- INFO: TTS generation for: {text}")
        try:
            tts_buffer = io.BytesIO()
            gTTS(text=text, lang=self._gtts_lang).write_to_fp(tts_buffer)
            tts_buffer.seek(0)
            song = AudioSegment.from_mp3(tts_buffer)
            song = speedup(song, playback_speed=1.2)
            final_buffer = io.BytesIO()
            song.export(final_buffer, format="mp3")
            final_buffer.seek(0)
            return final_buffer
        except Exception as e:
            print(f"--- ERROR: gTTS/pydub failed: {e}")
            return None
    # ğŸ’¡ğŸ’¡ğŸ’¡ --- [ë³µì› ì™„ë£Œ] --- ğŸ’¡ğŸ’¡ğŸ’¡

    def _transcribe(self, audio: np.ndarray) -> Optional[str]:
        """ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  ê³µë°±ì„ ì œê±°í•©ë‹ˆë‹¤."""
        if self._whisper_model is None:
            return None
        try:
            segments, _ = self._whisper_model.transcribe(
                audio, language="ko", beam_size=5, best_of=5,
                vad_filter=True, vad_parameters={"min_silence_duration_ms": 500}
            )
            text = " ".join(segment.text.strip() for segment in segments).replace(" ", "")
            return text if text else None
        except Exception as e:
            print(f"--- ERROR: Transcription failed: {e}")
            return None

    def _find_player(self, text: str) -> Optional[str]:
        if not text: return None
        for canonical_name, aliases in self.PLAYER_ALIASES.items():
            for alias in aliases:
                if alias in text:
                    return canonical_name 
        return None

    def _find_keyword(self, text: str) -> Optional[str]:
        if not text: return None
        for keyword, similar_words in self.KEYWORDS.items():
            for word in similar_words:
                if word in text:
                    return keyword
        return None

    def _get_reply(self, text: str, player_name: Optional[str], keyword: Optional[str]) -> str:
        if not text:
            return "ì˜ ëª» ë“¤ì—ˆì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?"
        if any(exit_kw in text for exit_kw in self._exit_keywords):
            return "ë„¤. ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤."
        if not player_name:
            return "ì£„ì†¡í•´ìš”, ì„ ìˆ˜ ì´ë¦„ì„ ë§ì”€í•´ì£¼ì„¸ìš”."
        if not keyword:
            return f"{player_name} ì„ ìˆ˜ì˜ ì–´ë–¤ ì •ë³´ê°€ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?"
        player_info = self.PLAYERS_DATA.get(player_name)
        value = player_info.get(keyword)
        if value is None:
            return f"ì£„ì†¡í•´ìš”, {player_name} ì„ ìˆ˜ì˜ {keyword} ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        if keyword == "íƒ€ìœ¨":
            return f"{player_name} ì„ ìˆ˜ì˜ íƒ€ìœ¨ì€ {value:.3f}ì…ë‹ˆë‹¤."
        elif keyword == "í™ˆëŸ°":
            return f"{player_name} ì„ ìˆ˜ì˜ í™ˆëŸ°ì€ {value}ê°œì…ë‹ˆë‹¤."
        elif keyword == "ì•ˆíƒ€":
            return f"{player_name} ì„ ìˆ˜ì˜ ì•ˆíƒ€ëŠ” {value}ê°œì…ë‹ˆë‹¤."
        else:
            return f"{player_name} ì„ ìˆ˜ì˜ {keyword}ì€(ëŠ”) {value}ì…ë‹ˆë‹¤."
            
    def process_ptt_audio(self, audio_file_storage) -> Dict[str, Any]:
        """
        PTT ì˜¤ë””ì˜¤ë¥¼ ì²˜ë¦¬í•˜ê³ , í…ìŠ¤íŠ¸ì™€ Base64 ì˜¤ë””ì˜¤ê°€ í¬í•¨ëœ JSONì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        user_text = None
        reply_text = None
        player_name = None
        keyword = None
        display_user_text = "..." 
        
        if not self._whisper_model or not TTS_AVAILABLE or not np:
            reply_text = "ìŒì„± ì²˜ë¦¬ ëª¨ë“ˆ(Whisper/Pydub)ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        else:
            try:
                # --- 1. ì˜¤ë””ì˜¤ ë¡œë“œ ë° ë³€í™˜ (pydub) ---
                audio_segment = AudioSegment.from_file(audio_file_storage)
                audio_segment = audio_segment.set_frame_rate(16000).set_channels(1).set_sample_width(2)
                samples = np.array(audio_segment.get_array_of_samples())
                audio_float = samples.astype(np.float32) / 32768.0

                # ğŸ’¡ğŸ’¡ğŸ’¡ --- [ì†ë„ ìµœì í™” 2] --- ğŸ’¡ğŸ’¡ğŸ’¡
                # Librosa ë¬µìŒ ì œê±°ë¥¼ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤. (ì£¼ì„ ì²˜ë¦¬)
                audio_to_transcribe = audio_float
                # if librosa:
                #     audio_float_trimmed, _ = librosa.effects.trim(audio_float, top_db=20)
                #     if len(audio_float_trimmed) > 1600: 
                #         audio_to_transcribe = audio_float_trimmed
                # ğŸ’¡ğŸ’¡ğŸ’¡ --- [ìµœì í™” ì™„ë£Œ] --- ğŸ’¡ğŸ’¡ğŸ’¡
                
                # --- 2. STT (ìŒì„± -> í…ìŠ¤íŠ¸) ---
                user_text = self._transcribe(audio_to_transcribe) 
                print(f"--- INFO: STT Raw Text: {user_text}")

                # --- 3. NLU (í…ìŠ¤íŠ¸ -> ì˜ë„) ---
                if user_text:
                    player_name = self._find_player(user_text)
                    keyword = self._find_keyword(user_text)

                # --- 4. í…ìŠ¤íŠ¸ ë³´ì • (NLU -> UI Text) ---
                if player_name and keyword:
                    display_user_text = f"{player_name} ì„ ìˆ˜ {keyword} ì•Œë ¤ì¤˜"
                elif user_text:
                    display_user_text = user_text
                
                # --- 5. ì‘ë‹µ ìƒì„± (ì˜ë„ -> AI í…ìŠ¤íŠ¸) ---
                reply_text = self._get_reply(user_text, player_name, keyword)

            except Exception as e:
                print(f"--- ERROR: Failed to process PTT audio: {e}")
                reply_text = "ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

        # ğŸ’¡ğŸ’¡ğŸ’¡ --- [gTTS ë¡œì§ ë³µì›] --- ğŸ’¡ğŸ’¡ğŸ’¡
        # --- 6. TTS (AI í…ìŠ¤íŠ¸ -> AI ìŒì„±) ë° Base64 ì¸ì½”ë”© ---
        audio_response_buffer = self._say(reply_text)
        audio_base64 = None
        if audio_response_buffer:
            audio_base64 = base64.b64encode(audio_response_buffer.read()).decode('utf-8')
        # ğŸ’¡ğŸ’¡ğŸ’¡ --- [ë³µì› ì™„ë£Œ] --- ğŸ’¡ğŸ’¡ğŸ’¡
        
        # --- 7. ìµœì¢… JSON ë°˜í™˜ ---
        return {
            "ok": True,
            "display_user_text": display_user_text,
            "reply_text": reply_text,
            "audio_base64": audio_base64 # ğŸ’¡ [ë³µì›] Base64 ì˜¤ë””ì˜¤ í¬í•¨
        }


# --- ì‹±ê¸€í†¤ ë° Blueprint ---
_singleton: Optional[VoiceAssistant] = None

def get_assistant() -> VoiceAssistant:
    """VoiceAssistant ì‹±ê¸€í†¤ ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _singleton
    if _singleton is None:
        _singleton = VoiceAssistant() # (ì„œë²„ ì˜¤ë¥˜ ìˆ˜ì •ë¨)
    return _singleton


voice_bp = Blueprint("voice", __name__)


@voice_bp.route("/api/voice/process_ptt", methods=["POST"])
def api_voice_process_ptt():
    """PTT ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë°›ì•„ ì²˜ë¦¬í•˜ê³  JSON ì‘ë‹µì„ ë°˜í™˜í•˜ëŠ” API"""
    va = get_assistant()
    
    audio_file = request.files.get('audio')
    if not audio_file:
        return jsonify({"ok": False, "error": "No audio file provided"}), 400

    response_data = va.process_ptt_audio(audio_file)

    if not response_data.get("ok"):
         return jsonify({"ok": False, "error": "Failed to process audio"}), 500

    return jsonify(response_data)
