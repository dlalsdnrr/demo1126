from __future__ import annotations

import os
import threading
import io
import base64
from typing import Optional, Dict, Any
import time
import difflib
import requests # <-- requests ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€

from flask import Blueprint, jsonify, request

# --- ETRI STT ì„¤ì • ë° ëª¨ë“ˆ ì„í¬íŠ¸ ---
ETRI_API_KEY = ""  # <-- ì—¬ê¸°ì— ë°œê¸‰ë°›ì€ ì‹¤ì œ í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
# httpsë¥¼ ì‚¬ìš©í•˜ì—¬ ë°©í™”ë²½ ì°¨ë‹¨ ë¬¸ì œë¥¼ ì¤„ì´ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
ETRI_API_URL = "http://epretx.etri.re.kr:8000/api/WiseASR_Recognition" 
USE_ETRI_STT = False 

try:
    import numpy as np
    # Whisper ê´€ë ¨ ëª¨ë“ˆ ì œê±°
    WhisperModel = None
    
    # requests ë° API Key ì„¤ì • í™•ì¸
    if requests and ETRI_API_KEY != "YOUR_ETRI_API_KEY":
        USE_ETRI_STT = True
        print("--- INFO: ETRI STT API enabled.")
    elif requests:
        print("Warning: ETRI_API_KEY not set. STT unavailable.")
    else:
        print("Warning: requests module not installed. STT unavailable.")

except Exception: # pragma: no cover
    np = None
    print("Warning: numpy not installed. Voice input unavailable.")

# --- TTS (edge-tts + pydub) í†µí•© ---
try:
    import edge_tts
    import asyncio
    from pydub import AudioSegment
    from pydub.effects import speedup
    TTS_AVAILABLE = True
    USE_EDGE_TTS = True
    print("--- INFO: edge-tts module loaded.")
except Exception: # pragma: no cover
    edge_tts = None
    AudioSegment = None
    speedup = None
    TTS_AVAILABLE = False
    USE_EDGE_TTS = False
    print("Warning: edge-tts, pydub or FFmpeg not installed. Audio processing/TTS unavailable.")
    
# Whisper ëª¨ë¸ ê´€ë ¨ ì „ì—­ ë³€ìˆ˜ ë³€ê²½
WHISPER_MODEL = None

def load_whisper_model():
    """ETRI API ì‚¬ìš©ìœ¼ë¡œ ì¸í•´ ì´ í•¨ìˆ˜ëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."""
    global WHISPER_MODEL
    print("--- INFO: Using ETRI STT. load_whisper_model skipped.")
    return None

async def speak_edge_tts_to_base64(text: str, voice="ko-KR-SunHiNeural", speed_factor=1.1) -> Optional[str]:
    """edge-ttsë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³  Base64 MP3ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not USE_EDGE_TTS or not AudioSegment:
        print("--- ERROR: edge-tts or pydub not available.")
        return None
    
    print(f"--- INFO: TTS generation (edge-tts) for: {text[:30]}...")
    
    try:
        communicate = edge_tts.Communicate(text, voice)
        
        audio_data = b""
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                audio_data += chunk["data"]
        
        audio_io = io.BytesIO(audio_data)
        song = AudioSegment.from_mp3(audio_io)
        
        if speed_factor != 1.0:
            song = speedup(song, playback_speed=speed_factor)
        
        output_buffer = io.BytesIO()
        song.export(output_buffer, format="mp3") 
        output_buffer.seek(0)
        
        return base64.b64encode(output_buffer.read()).decode('utf-8')
        
    except Exception as e:
        print(f"--- ERROR: edge-tts failed: {e}")
        return None

def get_tts_base64(text: str) -> Optional[str]:
    """asyncio.runì„ ì‚¬ìš©í•˜ì—¬ ë¹„ë™ê¸° TTS í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
    return loop.run_until_complete(speak_edge_tts_to_base64(text))


class VoiceAssistant:
    def __init__(self) -> None:
        # self._whisper_model = load_whisper_model() # STT ì—”ì§„ ë³€ê²½ìœ¼ë¡œ ì œê±°
        self._exit_keywords = []
        
        # --- í‚¤ì›Œë“œ ë° ì„ ìˆ˜ ë°ì´í„° ---
        self.KEYWORDS = {
            "íƒ€ìœ¨": ["íƒ€ìœ¨", "íƒ€ì´ìœ¨", "íƒ€ìœ ìœ¨", "íƒ€ìœ„", "íƒ€ì´ìœ„", "íƒ€ìœ ", "ë‹¤ìœ¨", "íƒ€ë‰¼", "íƒ€ë£°", "íƒ€ìœ ë¥¼", "íƒ€ìœ ë¦¬", "íƒ€ìœ¨ì€", "íƒ€ìœ¨ì´", 
                   "ë‹¤ìš”ë˜", "íƒ€ì´ìœ ", "íƒ€ìš”ë¥¼", "íƒ€ìš”ìœ¨", "ë‹¤ìœ¡", "ë‹¤ì´ìœ¨", "ë‹¤ì´ìœ ", "ë‹¤ìœ "],
            "í™ˆëŸ°": ["í™ˆëŸ°", "í™ëŸ°", "í™ˆë¡¬", "í™ë¡ ", "í›”ëŠ”", "í™ˆë¡ ", "í™ˆëˆˆ", "í—˜ë¡ ", "í˜¸ë„ˆ", "í™ˆë„ˆ", "í™ˆë„Œ", "í™ˆëŸ°ì€", "í™ˆëŸ°ì´", "í™ˆëŸ°ê°œìˆ˜",
                   "í™ë‚¨", "í™ˆë‚¨", "í™ëŸ¼", "í™ˆë„˜", "í ëŸ°", "ìŒë€", "ì—„ë‚¨"],
            "ì•ˆíƒ€": ["ì•ˆíƒ€", "ì•™íƒ€", "ì•ˆ íƒ€", "ì•”íƒ€", "ì•ˆíƒˆ", "ì•ˆíƒ‘", "ì•„íƒ€", "ì•ˆíƒ€ëŠ”", "ì•ˆíƒ€ê°€", "ì•„ì•ˆíƒ€", "ì•ˆíƒ€ê°œìˆ˜",
                   "ì•ˆë‚˜", "ì•ˆíƒ€ë¡œ", "ì•ˆë‹¤", "ì•ˆë‹¬", "ì•˜ë‹¤"]
        }
        
        self.PLAYER_ALIASES = {
            "ê¹€ì˜ì›…": ["ê¹€ì˜ì›…", "ê¸°ëª…ì›…", "ê¹€í˜•ì›…", "ê¹€ì˜", "ê¸°ëª…", "ê¹€ìš©ì›…", "ê¹€ì—¬ìš´", "ê¹€ì˜ì›…ì´", "ê¹€ì´ìš©", "ê¹€ì´ì›…", "ì´ëª…ìš°", "ê¹€ì—¬ë¦„"],
            "ë¦¬ë² ë¼í† ": ["ë¦¬ë² ë¼í† ", "ì´ë² ë¼í† ", "ë¦¬ë² ë¼", "ì´ë² ë¼", "ì´ë² ë¼ë„", "ë¦¬ë² ë¼í† ëŠ”", "ë¦¬ë² ë¼í† ì˜", "ë¦¬ë°°ë¼í† ", "ë‹ˆë² ë¼ë„", "ì´ë² ë¼ë„", "ë¦¬ë² ë¼ë„"],
            "í•˜ì£¼ì„": ["í•˜ì£¼ì„", "ì•„ì£¼ì„", "í™”ì£¼ì„", "í•˜ì£¼ì†Œ", "í•˜ì£¼", "í•˜ì£¼ì„ì´", "í•˜ì£¼ì„ì€", "í•˜ì¦ˆì„", "í•˜ë‚˜ íˆ¬ì†", "í•˜ë‚˜íˆ¬ì†", "ì•„ë‚˜ íˆ¬ì†", "ì•„ì£¼ì„"],
            "ê¹€íƒœí›ˆ": ["ê¹€íƒœí›ˆ", "ê¹€íƒœìš´", "ê¹€íƒœí¬", "ê¹€ëŒ€í›ˆ", "ê¹€ëŒ€ìš´", "ê¹€íƒœí›ˆì´", "ê¹€íƒœí›ˆì€", "ê¹€ëŒ€í›ˆì´", "ê¹€íƒœìš°", "ê¹€íƒœ", "ê¹€ëŒ€ìš´"],
            "ìµœì¬í›ˆ": ["ìµœì¬í›ˆ", "ì²´ì¬í›ˆ", "ì·Œì¬í›ˆ", "ìµœì¬", "ìµœì¬í›ˆì´", "ìµœì¬í›ˆì€", "ìµœëŒ€í›ˆ", "ìµœì •ì€", "ì±„ì¬í›ˆ", "ì²´ì œí›ˆ", "ìµœì €ì˜¨"]
        }
        
        self.PLAYERS_DATA = {
            "ê¹€ì˜ì›…": { "íƒ€ìœ¨": 0.643, "í™ˆëŸ°": 3, "ì•ˆíƒ€": 9 },
            "ë¦¬ë² ë¼í† ": { "íƒ€ìœ¨": 0.467, "í™ˆëŸ°": 1, "ì•ˆíƒ€": 7 },
            "í•˜ì£¼ì„": { "íƒ€ìœ¨": 0.438, "í™ˆëŸ°": 0, "ì•ˆíƒ€": 7 },
            "ê¹€íƒœí›ˆ": { "íƒ€ìœ¨": 0.429, "í™ˆëŸ°": 2, "ì•ˆíƒ€": 6 },
            "ìµœì¬í›ˆ": { "íƒ€ìœ¨": 0.385, "í™ˆëŸ°": 0, "ì•ˆíƒ€": 5 }
        }

    # --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
    def _fuzzy_match(self, text: str, candidates: list[str], threshold=0.65) -> bool:
        """í¼ì§€ ë§¤ì¹­ì„ í†µí•´ í…ìŠ¤íŠ¸ì™€ í›„ë³´ ë‹¨ì–´ë¥¼ ë¹„êµí•©ë‹ˆë‹¤."""
        for word in candidates:
            if word in text:
                return True
        for candidate in candidates:
            if difflib.SequenceMatcher(None, text, candidate).ratio() > threshold:
                return True
        return False

    def _transcribe_etri(self, audio_data: bytes) -> Optional[str]:
        """ETRI STT APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        if not USE_ETRI_STT or not requests:
            print("--- ERROR: ETRI STT not available or requests module missing.")
            return None
            
        print("--- INFO: Sending audio to ETRI STT API...")
        
        request_json = {
            "argument": {
                "language_code": "korean",
                "audio": base64.b64encode(audio_data).decode('utf-8') # Base64 ì¸ì½”ë”©
            }
        }
        
        http_headers = {
            "Authorization": ETRI_API_KEY,
            "Content-Type": "application/json; charset=UTF-8",
        }
        
        try:
            response = requests.post(ETRI_API_URL, headers=http_headers, json=request_json, timeout=10) # íƒ€ì„ì•„ì›ƒ 10ì´ˆ ì„¤ì •
            response.raise_for_status() # HTTP ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì˜ˆì™¸ ë°œìƒ
            
            result_json = response.json()
            
            # [ë””ë²„ê¹…] ETRI APIì˜ ì „ì²´ ì‘ë‹µì„ í™•ì¸í•©ë‹ˆë‹¤.
            print(f"--- DEBUG: ETRI Full Response: {result_json}")
            
            # ETRI API ì‘ë‹µ í˜•ì‹ í™•ì¸ (result: 0ì´ ì„±ê³µ)
            if result_json.get("result") == 0:
                # ğŸ’¡ [ìˆ˜ì •ë¨] ETRI ì‘ë‹µ í‚¤ 'recognized_text' -> 'recognized'
                recognized_text = result_json.get("return_object", {}).get("recognized", "").strip() 
                return recognized_text.lower() if recognized_text else None
            else:
                # API ì²˜ë¦¬ ì˜¤ë¥˜ (ì˜ˆ: API í‚¤ ì˜¤ë¥˜, í• ë‹¹ëŸ‰ ì´ˆê³¼ ë“±)
                error_msg = result_json.get("return_object", {}).get("error_text", "Unknown ETRI API error")
                print(f"--- ERROR: ETRI STT API returned error: {error_msg}")
                return None
            
        except requests.exceptions.RequestException as e:
            # HTTP ì—°ê²° ì˜¤ë¥˜ (Connection refused, Timeout ë“±)
            print(f"--- ERROR: HTTP request to ETRI STT failed: {e}")
            return None
        except Exception as e:
            print(f"--- ERROR: ETRI STT processing failed: {e}")
            return None
            
    def _transcribe(self, audio: Any) -> Optional[str]:
        """STT ì—”ì§„ ë³€ê²½ìœ¼ë¡œ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ."""
        print("--- WARNING: _transcribe (Whisper) function called, but ETRI STT is active.")
        return None

    def _find_player(self, text: str) -> Optional[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì„ ìˆ˜ ì´ë¦„ì„ ì°¾ìŠµë‹ˆë‹¤."""
        if not text: return None
        for canonical_name, aliases in self.PLAYER_ALIASES.items():
            if self._fuzzy_match(text, aliases):
                return canonical_name
        return None

    def _find_keyword(self, text: str) -> Optional[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ í‚¤ì›Œë“œ(íƒ€ìœ¨, í™ˆëŸ° ë“±)ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
        if not text: return None
        if "ë‹¤ìš”ë˜" in text:
            return "íƒ€ìœ¨"
            
        for keyword, similar_words in self.KEYWORDS.items():
            if self._fuzzy_match(text, similar_words):
                return keyword
        return None

    def _get_reply(self, text: str, player_name: Optional[str], keyword: Optional[str]) -> str:
        """ë¶„ì„ëœ ì˜ë„ë¥¼ ë°”íƒ•ìœ¼ë¡œ AI ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        if not text:
            return "ì˜ ëª» ë“¤ì—ˆì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?"
        
        if not player_name:
            return "ì£„ì†¡í•´ìš”, ì„ ìˆ˜ ì´ë¦„ì„ ë§ì”€í•´ì£¼ì„¸ìš”."
        if not keyword:
            return f"{player_name} ì„ ìˆ˜ì˜ ì–´ë–¤ ì •ë³´ê°€ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?"
            
        player_info = self.PLAYERS_DATA.get(player_name)
        if player_info is None:
            return f"ì£„ì†¡í•´ìš”, {player_name} ì„ ìˆ˜ì˜ ê¸°ë¡ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
            
        value = player_info.get(keyword)
        if value is None:
            return f"ì£„ì†¡í•´ìš”, {player_name} ì„ ìˆ˜ì˜ {keyword} ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        if keyword == "íƒ€ìœ¨":
            return f"{player_name} ì„ ìˆ˜ì˜ íƒ€ìœ¨ì€ {value:.3f}ì…ë‹ˆë‹¤."
        elif keyword == "í™ˆëŸ°":
            return f"{player_name} ì„ ìˆ˜ì˜ í™ˆëŸ°ì€ {value}ê°œì…ë‹ˆë‹¤."
        elif keyword == "ì•ˆíƒ€":
            return f"{player_name} ì„ ìˆ˜ì˜ ì•ˆíƒ€ëŠ” {value}ê°œì…ë‹ˆë‹¤."
        else:
            return f"{player_name} ì„ ìˆ˜ì˜ {keyword}ì€(ëŠ”) {value}ì…ë‹ˆë‹¤."
            
    def process_ptt_audio(self, audio_file_storage) -> Dict[str, Any]:
        """PTT ì˜¤ë””ì˜¤ë¥¼ ì²˜ë¦¬í•˜ê³ , í…ìŠ¤íŠ¸ì™€ Base64 ì˜¤ë””ì˜¤ê°€ í¬í•¨ëœ JSONì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        start_time = time.time()

        user_text = None
        reply_text = None
        player_name = None
        keyword = None
        display_user_text = "..."
        audio_base64 = None
            
        # ğŸ’¡ STT ëª¨ë“ˆ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ ë¡œì§ì„ ETRI STT ê¸°ì¤€ìœ¼ë¡œ ë³€ê²½
        if not USE_ETRI_STT or not AudioSegment or not TTS_AVAILABLE:
            reply_text = "ìŒì„± ì²˜ë¦¬ ëª¨ë“ˆ(ETRI STT/Pydub/Edge-TTS)ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ê±°ë‚˜ í•„ìš”í•œ ëª¨ë“ˆ/FFmpegì„ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
        else:
            try:
                # --- 1. ì˜¤ë””ì˜¤ ë¡œë“œ ë° ETRI STTìš© WAV ë°ì´í„°ë¡œ ë³€í™˜ (pydub) ---
                load_start = time.time()
                audio_segment = AudioSegment.from_file(audio_file_storage)
                
                # 16kHz, Mono, 16-bit short-int (2 bytes) RAW PCMìœ¼ë¡œ ì„¤ì • (ETRI ìš”êµ¬ ìŠ¤í™)
                audio_segment = audio_segment.set_frame_rate(16000).set_channels(1).set_sample_width(2)
                
                # ğŸ’¡ [ìˆ˜ì •ë¨] AudioSegmentë¥¼ RAW PCMì´ ì•„ë‹Œ 'wav' í¬ë§·ì˜ ë°”ì´íŠ¸ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
                # ETRI APIëŠ” íŒŒì¼ í—¤ë”ê°€ í¬í•¨ëœ ì™„ì „í•œ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ê¸°ëŒ€í•©ë‹ˆë‹¤.
                wav_audio_io = io.BytesIO()
                audio_segment.export(wav_audio_io, format="wav") # <-- â˜…â˜…â˜… format="raw"ì—ì„œ "wav"ë¡œ ë³€ê²½ â˜…â˜…â˜…
                audio_data_for_etri = wav_audio_io.getvalue()
                
                print(f"--- TIME: Audio Load/Convert for ETRI (WAV): {time.time() - load_start:.3f}s")
                
                # --- 2. STT (ìŒì„± -> í…ìŠ¤íŠ¸) - ETRI API ì‚¬ìš© ---
                stt_start = time.time()
                user_text = self._transcribe_etri(audio_data_for_etri) # ETRI STT í•¨ìˆ˜ í˜¸ì¶œ (WAV ë°”ì´íŠ¸ ì „ë‹¬)
                print(f"--- TIME: STT Transcription (ETRI): {time.time() - stt_start:.3f}s")
                print(f"--- INFO: STT Text: {user_text}")

                # --- 3. NLU (í…ìŠ¤íŠ¸ -> ì˜ë„) ---
                nlu_start = time.time()
                if user_text:
                    player_name = self._find_player(user_text)
                    keyword = self._find_keyword(user_text)
                print(f"--- TIME: NLU Processing: {time.time() - nlu_start:.3f}s")

                # --- 4. í…ìŠ¤íŠ¸ ë³´ì • ---
                if player_name and keyword:
                    display_user_text = f"{player_name} ì„ ìˆ˜ {keyword} ì•Œë ¤ì¤˜"
                elif user_text:
                    display_user_text = user_text
                
                # --- 5. ì‘ë‹µ ìƒì„± ---
                reply_text = self._get_reply(user_text, player_name, keyword)
                
            except Exception as e:
                print(f"--- ERROR: Failed to process PTT audio: {e}")
                reply_text = "ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

        # --- 6. TTS (AI í…ìŠ¤íŠ¸ -> AI ìŒì„±) ë° Base64 ì¸ì½”ë”© ---
        tts_start = time.time()
        if TTS_AVAILABLE and reply_text:
            audio_base64 = get_tts_base64(reply_text)
        else:
            audio_base64 = None
            if not TTS_AVAILABLE:
                print("--- WARNING: TTS is not available, skipping audio generation.")
        
        print(f"--- TIME: TTS Generation: {time.time() - tts_start:.3f}s")
        
        total_time = time.time() - start_time
        print(f"--- TIME: Total process time: {total_time:.3f}s")
            
        # --- 7. ìµœì¢… JSON ë°˜í™˜ ---
        return {
            "ok": True,
            "display_user_text": display_user_text,
            "reply_text": reply_text,
            "audio_base64": audio_base64
        }


# --- ì‹±ê¸€í†¤ ë° Blueprint (ë³€ê²½ ì—†ìŒ) ---
_singleton: Optional[VoiceAssistant] = None

def get_assistant() -> VoiceAssistant:
    """VoiceAssistant ì‹±ê¸€í†¤ ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _singleton
    if _singleton is None:
        _singleton = VoiceAssistant()
    return _singleton


voice_bp = Blueprint("voice", __name__)


@voice_bp.route("/api/voice/process_ptt", methods=["POST"])
def api_voice_process_ptt():
    """PTT ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë°›ì•„ ì²˜ë¦¬í•˜ê³  JSON ì‘ë‹µì„ ë°˜í™˜í•˜ëŠ” API"""
    va = get_assistant()
    
    audio_file = request.files.get('audio')
    if not audio_file:
        return jsonify({"ok": False, "error": "No audio file provided"}), 400

    response_data = va.process_ptt_audio(audio_file)

    if not response_data.get("ok"):
        return jsonify({"ok": False, "error": "Failed to process audio"}), 500

    return jsonify(response_data)
